INFO:     Will watch for changes in these directories: ['/Users/naman/Enculture-Intelligence-Platform/backend']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [15295] using WatchFiles
INFO:     Started server process [15312]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
ðŸš€ Starting Enculture Backend API...
Environment: development
Debug Mode: True
INFO:     127.0.0.1:63250 - "GET /health HTTP/1.1" 200 OK
INFO:     127.0.0.1:63253 - "GET /health HTTP/1.1" 200 OK
2025-09-07 08:20:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:20:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:20:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11697b7f0>
2025-09-07 08:20:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11697b7f0>
2025-09-07 08:20:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:20:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:20:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11698dd60>
2025-09-07 08:20:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11698dd60>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_e5b117e2a41bb5fe4ab7f88910dda90a'), (b'openai-processing-ms', b'5720'), (b'x-envoy-upstream-service-time', b'5723'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9yL0XBG3g4es1EqvpDbGKqvRx2bJjY4Otw9FLvIobdo-1757258446-1.0.1.1-bRRocFbaiXfr1q_q4j9fOz0Bz4eQONohUFDVHY2mP12e8JZiJoYalOUZk4VRMg7Mg422HbwUBY0pBD.xUIly_hGgt6hm3LBPo5G7mMtr9D8; path=/; expires=Sun, 07-Sep-25 15:50:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.a06x.adOi88fosn0L0Jp71V0ZfI_mJ72gr8n3ZPTSE-1757258446343-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b731054b40201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_e5b117e2a41bb5fe4ab7f88910dda90a'), (b'openai-processing-ms', b'5720'), (b'x-envoy-upstream-service-time', b'5723'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9yL0XBG3g4es1EqvpDbGKqvRx2bJjY4Otw9FLvIobdo-1757258446-1.0.1.1-bRRocFbaiXfr1q_q4j9fOz0Bz4eQONohUFDVHY2mP12e8JZiJoYalOUZk4VRMg7Mg422HbwUBY0pBD.xUIly_hGgt6hm3LBPo5G7mMtr9D8; path=/; expires=Sun, 07-Sep-25 15:50:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.a06x.adOi88fosn0L0Jp71V0ZfI_mJ72gr8n3ZPTSE-1757258446343-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b731054b40201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63255 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:63261 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
2025-09-07 08:20:46 - app.api.v1.endpoints.chat - INFO - Received streaming chat request for thread f71a8f6e-84da-40d3-8a8d-766fda86638e
2025-09-07 08:20:46 - app.api.v1.endpoints.chat - INFO - Received streaming chat request for thread f71a8f6e-84da-40d3-8a8d-766fda86638e
INFO:     127.0.0.1:63263 - "POST /api/v1/chat/stream-with-thread?thread_id=f71a8f6e-84da-40d3-8a8d-766fda86638e&prompt=hello HTTP/1.1" 200 OK
2025-09-07 08:20:46 - app.services.openai_service - INFO - Initiating gpt-4.1 Responses API call with web search: True
2025-09-07 08:20:46 - app.services.openai_service - INFO - Initiating gpt-4.1 Responses API call with web search: True
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:46 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449484'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'68ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_13f5eabc380e15ff28070df88a959f08'), (b'openai-processing-ms', b'1517'), (b'x-envoy-upstream-service-time', b'1521'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7312b8b66201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449484'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'68ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_13f5eabc380e15ff28070df88a959f08'), (b'openai-processing-ms', b'1517'), (b'x-envoy-upstream-service-time', b'1521'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7312b8b66201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:20:48 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:20:49 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:20:49 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63292 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
INFO:     127.0.0.1:63292 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:52 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63292 - "OPTIONS /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63294 - "OPTIONS /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63292 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63294 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63294 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63292 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:20:52 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63306 - "GET /api/v1/chat/threads/f71a8f6e-84da-40d3-8a8d-766fda86638e HTTP/1.1" 200 OK
2025-09-07 08:20:56 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_3a9129f02a6f2a20759dc5da3ab2fca5'), (b'openai-processing-ms', b'7515'), (b'x-envoy-upstream-service-time', b'7517'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7314d8c88201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:20:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_3a9129f02a6f2a20759dc5da3ab2fca5'), (b'openai-processing-ms', b'7515'), (b'x-envoy-upstream-service-time', b'7517'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7314d8c88201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63291 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:20:59 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:21:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_91c84766d63fe76a2712c09e079e4af3'), (b'openai-processing-ms', b'6882'), (b'x-envoy-upstream-service-time', b'6887'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7317e8886201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:21:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_91c84766d63fe76a2712c09e079e4af3'), (b'openai-processing-ms', b'6882'), (b'x-envoy-upstream-service-time', b'6887'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7317e8886201d-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:21:06 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63291 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:22:19 - httpcore.connection - DEBUG - close.started
2025-09-07 08:22:19 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:63469 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:22:19 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:22:19 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:22:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:22:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:22:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116d99d90>
2025-09-07 08:22:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116d99d90>
2025-09-07 08:22:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:22:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:22:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116d99d30>
2025-09-07 08:22:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116d99d30>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:22:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:22:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_a4cf466b579dca139a80d0ac9ad82b0d'), (b'openai-processing-ms', b'6180'), (b'x-envoy-upstream-service-time', b'6183'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b73372db73b9f7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:22:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_a4cf466b579dca139a80d0ac9ad82b0d'), (b'openai-processing-ms', b'6180'), (b'x-envoy-upstream-service-time', b'6183'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b73372db73b9f7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:22:26 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63467 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:22:42 - httpcore.connection - DEBUG - close.started
2025-09-07 08:22:42 - httpcore.connection - DEBUG - close.started
2025-09-07 08:22:42 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:22:42 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:63478 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:22:42 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:22:42 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:22:42 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9f10>
2025-09-07 08:22:42 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9f10>
2025-09-07 08:22:42 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:22:42 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:22:42 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9790>
2025-09-07 08:22:42 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9790>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:22:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:22:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_27addbb39827db9671e2541484d7c8a1'), (b'openai-processing-ms', b'5532'), (b'x-envoy-upstream-service-time', b'5537'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b734006de67675-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:22:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_27addbb39827db9671e2541484d7c8a1'), (b'openai-processing-ms', b'5532'), (b'x-envoy-upstream-service-time', b'5537'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b734006de67675-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:22:48 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63477 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/703a9f6e-8bf2-48d3-a65e-b8f3e962979a HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/703a9f6e-8bf2-48d3-a65e-b8f3e962979a HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:34 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/7127fbaa-4223-4542-a10a-de5530c33ca0 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/7127fbaa-4223-4542-a10a-de5530c33ca0 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:35 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:23:35 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/4a29e15e-7748-4780-8940-2066f9906365 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/4a29e15e-7748-4780-8940-2066f9906365 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:36 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/2876de5e-7246-4ee9-9871-7d76ea9525e6 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/2876de5e-7246-4ee9-9871-7d76ea9525e6 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:36 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/cfc41bac-5624-41dd-bbd7-56145e087080 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/cfc41bac-5624-41dd-bbd7-56145e087080 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:36 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/c9f8f7a9-7d25-40ba-b259-84bccfe17faa HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/c9f8f7a9-7d25-40ba-b259-84bccfe17faa HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/a3c8cbbc-9d74-458f-adc7-a71bc2bea69a HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/a3c8cbbc-9d74-458f-adc7-a71bc2bea69a HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:37 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63515 - "OPTIONS /api/v1/chat/threads/b6e49776-1bc5-4b04-92cf-8d0949041add HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "DELETE /api/v1/chat/threads/b6e49776-1bc5-4b04-92cf-8d0949041add HTTP/1.1" 200 OK
INFO:     127.0.0.1:63515 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:37 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63518 - "OPTIONS /api/v1/chat/threads/95eb6fb4-742a-4d32-9f9a-e09d7a6a74ce HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "DELETE /api/v1/chat/threads/95eb6fb4-742a-4d32-9f9a-e09d7a6a74ce HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:38 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/33d8bf6c-1ca5-4fca-ace6-32b2f8c013e3 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/33d8bf6c-1ca5-4fca-ace6-32b2f8c013e3 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "OPTIONS /api/v1/chat/threads/33d8bf6c-1ca5-4fca-ace6-32b2f8c013e3 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "DELETE /api/v1/chat/threads/33d8bf6c-1ca5-4fca-ace6-32b2f8c013e3 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/33d8bf6c-1ca5-4fca-ace6-32b2f8c013e3 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:39 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63518 - "OPTIONS /api/v1/chat/threads/b9ccfb60-7d00-4394-afb7-014fbdc43ebd HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "DELETE /api/v1/chat/threads/b9ccfb60-7d00-4394-afb7-014fbdc43ebd HTTP/1.1" 200 OK
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:23:40 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:23:40 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
INFO:     127.0.0.1:63518 - "GET /api/v1/chat/threads/f71a8f6e-84da-40d3-8a8d-766fda86638e HTTP/1.1" 200 OK
2025-09-07 08:25:15 - httpcore.connection - DEBUG - close.started
2025-09-07 08:25:15 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:63564 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:25:15 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:25:15 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:25:15 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:25:15 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:25:15 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04370>
2025-09-07 08:25:15 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04370>
2025-09-07 08:25:15 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:25:15 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:25:15 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f046d0>
2025-09-07 08:25:15 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f046d0>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:15 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_6f0ffdc1df148500739477a777cde867'), (b'openai-processing-ms', b'5079'), (b'x-envoy-upstream-service-time', b'5083'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b737bb18e89b5a-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_6f0ffdc1df148500739477a777cde867'), (b'openai-processing-ms', b'5079'), (b'x-envoy-upstream-service-time', b'5083'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b737bb18e89b5a-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:20 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63563 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:25:37 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:63584 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:25:37 - httpcore.connection - DEBUG - close.started
2025-09-07 08:25:37 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:25:37 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:25:37 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:25:37 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:25:37 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9760>
2025-09-07 08:25:37 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9760>
2025-09-07 08:25:37 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:25:37 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:25:37 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04fa0>
2025-09-07 08:25:37 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04fa0>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:37 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:25:40 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:63607 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63609 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:25:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116edd670>
2025-09-07 08:25:40 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116edd670>
2025-09-07 08:25:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:25:40 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
INFO:     127.0.0.1:63609 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63607 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
2025-09-07 08:25:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef76d0>
2025-09-07 08:25:40 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef76d0>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:40 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63609 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63607 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:25:40 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63607 - "GET /api/v1/chat/threads/f5617c77-7f3f-4238-839d-93f69c4157b7 HTTP/1.1" 200 OK
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_349aea059614c1e5f30fe8dd5a4a4925'), (b'openai-processing-ms', b'6301'), (b'x-envoy-upstream-service-time', b'6306'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b73846fa8375b6-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_349aea059614c1e5f30fe8dd5a4a4925'), (b'openai-processing-ms', b'6301'), (b'x-envoy-upstream-service-time', b'6306'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b73846fa8375b6-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:44 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:46 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_a15e96a3f81260eaf2cd9874d6d6d00c'), (b'openai-processing-ms', b'6195'), (b'x-envoy-upstream-service-time', b'6198'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b738569998f4e1-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_a15e96a3f81260eaf2cd9874d6d6d00c'), (b'openai-processing-ms', b'6195'), (b'x-envoy-upstream-service-time', b'6198'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b738569998f4e1-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63584 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_c07dfa148e9c23a32610485a724ab620'), (b'openai-processing-ms', b'8108'), (b'x-envoy-upstream-service-time', b'8124'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7387dfb0b75b6-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:25:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_c07dfa148e9c23a32610485a724ab620'), (b'openai-processing-ms', b'8108'), (b'x-envoy-upstream-service-time', b'8124'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7387dfb0b75b6-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:54 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:25:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:25:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:25:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:25:54 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:63584 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:31:27 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:63772 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:31:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:31:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:31:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:31:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:31:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:31:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116e3f5e0>
2025-09-07 08:31:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116e3f5e0>
2025-09-07 08:31:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:31:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:31:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef100>
2025-09-07 08:31:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef100>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:31:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:31:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ef9fe19f6d17925300d49776cf84b914'), (b'openai-processing-ms', b'3867'), (b'x-envoy-upstream-service-time', b'3870'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b740d2fe6b6c8e-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:31:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ef9fe19f6d17925300d49776cf84b914'), (b'openai-processing-ms', b'3867'), (b'x-envoy-upstream-service-time', b'3870'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b740d2fe6b6c8e-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:31:31 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63771 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:31:54 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:63808 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:31:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:31:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:31:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:31:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:31:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:31:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1af0>
2025-09-07 08:31:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1af0>
2025-09-07 08:31:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:31:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:31:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1d60>
2025-09-07 08:31:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1d60>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:31:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63815 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_bdab8ce4eef0cfbdc013812158d43dfa'), (b'openai-processing-ms', b'5550'), (b'x-envoy-upstream-service-time', b'5553'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7417c8e629b6b-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_bdab8ce4eef0cfbdc013812158d43dfa'), (b'openai-processing-ms', b'5550'), (b'x-envoy-upstream-service-time', b'5553'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7417c8e629b6b-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63807 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:32:00 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_15f9b29931ab0694c9890ec9002df520'), (b'openai-processing-ms', b'6893'), (b'x-envoy-upstream-service-time', b'6895'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b741a06e459b6b-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_15f9b29931ab0694c9890ec9002df520'), (b'openai-processing-ms', b'6893'), (b'x-envoy-upstream-service-time', b'6895'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b741a06e459b6b-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:32:07 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63815 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:63862 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:32:41 - httpcore.connection - DEBUG - close.started
2025-09-07 08:32:41 - httpcore.connection - DEBUG - close.started
2025-09-07 08:32:41 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:32:41 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:32:41 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:32:41 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:32:41 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116effca0>
2025-09-07 08:32:41 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116effca0>
2025-09-07 08:32:41 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:32:41 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:32:41 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9910>
2025-09-07 08:32:41 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9910>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:32:41 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_1150863fff8d9d5bfe908dd067ac5d39'), (b'openai-processing-ms', b'5535'), (b'x-envoy-upstream-service-time', b'5538'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7429f3968ec68-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:32:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_1150863fff8d9d5bfe908dd067ac5d39'), (b'openai-processing-ms', b'5535'), (b'x-envoy-upstream-service-time', b'5538'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7429f3968ec68-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:32:47 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63861 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:32:58 - httpcore.connection - DEBUG - close.started
2025-09-07 08:32:58 - httpcore.connection - DEBUG - close.started
2025-09-07 08:32:58 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:63877 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:32:58 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:32:58 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:32:58 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:32:58 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f072e0>
2025-09-07 08:32:58 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f072e0>
2025-09-07 08:32:58 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:32:58 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
INFO:     127.0.0.1:63877 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:32:58 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f07250>
2025-09-07 08:32:58 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f07250>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:32:58 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63877 - "OPTIONS /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63880 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63880 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
2025-09-07 08:33:00 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63880 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63880 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:33:04 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b674338d97705c78b22b1ced6a81d795'), (b'openai-processing-ms', b'12597'), (b'x-envoy-upstream-service-time', b'12600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b743076a2fc373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b674338d97705c78b22b1ced6a81d795'), (b'openai-processing-ms', b'12597'), (b'x-envoy-upstream-service-time', b'12600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b743076a2fc373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63875 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:10 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:33:13 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:33:13 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef130>
2025-09-07 08:33:13 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef130>
2025-09-07 08:33:13 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:33:13 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
INFO:     127.0.0.1:63901 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63901 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:33:13 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6a60>
2025-09-07 08:33:13 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6a60>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:13 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63901 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63903 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
2025-09-07 08:33:14 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63903 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63903 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:33:14 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_9c0a0b3dd7d159cb31be55efdd13428b'), (b'openai-processing-ms', b'7339'), (b'x-envoy-upstream-service-time', b'7342'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74356e905c373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_9c0a0b3dd7d159cb31be55efdd13428b'), (b'openai-processing-ms', b'7339'), (b'x-envoy-upstream-service-time', b'7342'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74356e905c373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2af161bf7d4fb7e3520fad60ea64feed'), (b'openai-processing-ms', b'6601'), (b'x-envoy-upstream-service-time', b'6605'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74368db8ddef7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2af161bf7d4fb7e3520fad60ea64feed'), (b'openai-processing-ms', b'6601'), (b'x-envoy-upstream-service-time', b'6605'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74368db8ddef7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63898 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:20 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_0e45155e7d2389e931122c3c45e8bdd7'), (b'openai-processing-ms', b'7124'), (b'x-envoy-upstream-service-time', b'7128'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b743938bc6c373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:33:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_0e45155e7d2389e931122c3c45e8bdd7'), (b'openai-processing-ms', b'7124'), (b'x-envoy-upstream-service-time', b'7128'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b743938bc6c373-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:33:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:33:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:33:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:33:27 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:63898 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:33:58 - httpcore.connection - DEBUG - close.started
2025-09-07 08:33:58 - httpcore.connection - DEBUG - close.started
2025-09-07 08:33:58 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:33:58 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:33:58 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:33:58 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:63916 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:33:58 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116efafd0>
2025-09-07 08:33:58 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116efafd0>
2025-09-07 08:33:58 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:33:58 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:33:58 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cbae80>
2025-09-07 08:33:58 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cbae80>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:33:58 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_88fd9531515ede2d8ede55804f1cbafe'), (b'openai-processing-ms', b'7837'), (b'x-envoy-upstream-service-time', b'7841'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74481ec3b76aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_88fd9531515ede2d8ede55804f1cbafe'), (b'openai-processing-ms', b'7837'), (b'x-envoy-upstream-service-time', b'7841'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74481ec3b76aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:06 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63914 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:08 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63923 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:13 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:34:13 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:63932 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:13 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef78e0>
2025-09-07 08:34:13 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef78e0>
2025-09-07 08:34:13 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:34:13 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:34:13 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cba1f0>
2025-09-07 08:34:13 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cba1f0>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:13 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63936 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2643596a1b559c64d3b7049494a4496e'), (b'openai-processing-ms', b'7596'), (b'x-envoy-upstream-service-time', b'7600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744c10f1276aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2643596a1b559c64d3b7049494a4496e'), (b'openai-processing-ms', b'7596'), (b'x-envoy-upstream-service-time', b'7600'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744c10f1276aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63921 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:16 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_86d68ad0a989bbd8d7ab530d4d84dc22'), (b'openai-processing-ms', b'4722'), (b'x-envoy-upstream-service-time', b'4737'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744e19c7cec4c-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_86d68ad0a989bbd8d7ab530d4d84dc22'), (b'openai-processing-ms', b'4722'), (b'x-envoy-upstream-service-time', b'4737'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744e19c7cec4c-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:18 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63930 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_df7cc7a1f2d3520c1a80a708f0660513'), (b'openai-processing-ms', b'3427'), (b'x-envoy-upstream-service-time', b'3430'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744f1cab776aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_df7cc7a1f2d3520c1a80a708f0660513'), (b'openai-processing-ms', b'3427'), (b'x-envoy-upstream-service-time', b'3430'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b744f1cab776aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:20 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63921 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63952 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:21 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63952 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63952 - "OPTIONS /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63954 - "OPTIONS /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63954 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63952 - "POST /api/v1/chat/threads HTTP/1.1" 200 OK
INFO:     127.0.0.1:63952 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63954 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:21 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:34:24 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/73fa8d47-0a62-4faa-b992-5ee36936c0e8 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/73fa8d47-0a62-4faa-b992-5ee36936c0e8 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/73fa8d47-0a62-4faa-b992-5ee36936c0e8 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/4053e722-116b-4201-a5aa-0260dcc1e519 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/4053e722-116b-4201-a5aa-0260dcc1e519 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:24 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/868f2d5b-9b11-430c-9968-6f63baba9507 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/868f2d5b-9b11-430c-9968-6f63baba9507 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/4bf4a708-907c-4a2d-ae1e-98ae7aec45bc HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/4bf4a708-907c-4a2d-ae1e-98ae7aec45bc HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:25 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/0e263657-040c-44ef-a676-a4dc6dcdcf4b HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/0e263657-040c-44ef-a676-a4dc6dcdcf4b HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/a70498be-8bd4-46bb-98f6-731612d07175 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/a70498be-8bd4-46bb-98f6-731612d07175 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:25 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/d82e1a10-aeda-41ca-ac3d-a81218877354 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/d82e1a10-aeda-41ca-ac3d-a81218877354 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:26 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
INFO:     127.0.0.1:63956 - "OPTIONS /api/v1/chat/threads/fdaf9d60-4b71-40dd-b6d8-1cebefaa220e HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "DELETE /api/v1/chat/threads/fdaf9d60-4b71-40dd-b6d8-1cebefaa220e HTTP/1.1" 200 OK
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:34:26 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_0435683a1225f2b484328dc61d81e197'), (b'openai-processing-ms', b'5345'), (b'x-envoy-upstream-service-time', b'5348'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7450e5d4b76aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_0435683a1225f2b484328dc61d81e197'), (b'openai-processing-ms', b'5345'), (b'x-envoy-upstream-service-time', b'5348'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7450e5d4b76aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:26 - httpcore.connection - DEBUG - close.started
2025-09-07 08:34:26 - httpcore.connection - DEBUG - close.started
2025-09-07 08:34:26 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:34:26 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:63950 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:34:26 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:63950 - "GET /api/v1/chat/threads/culture-001 HTTP/1.1" 200 OK
2025-09-07 08:34:30 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ff54267cf4c0ffb94ccc8db4a5670525'), (b'openai-processing-ms', b'5581'), (b'x-envoy-upstream-service-time', b'5585'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b745311ed876aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:34:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ff54267cf4c0ffb94ccc8db4a5670525'), (b'openai-processing-ms', b'5581'), (b'x-envoy-upstream-service-time', b'5585'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b745311ed876aa-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:34:32 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:63956 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:01 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/data/chat_threads.json')}
2025-09-07 08:37:02 - watchfiles.main - DEBUG - 1 change detected: {(<Change.modified: 2>, '/Users/naman/Enculture-Intelligence-Platform/backend/.DS_Store')}
INFO:     127.0.0.1:64054 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:03 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:03 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:03 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:03 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0a430>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0a430>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64058 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f06d00>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f06d00>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f040a0>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f040a0>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04c10>
2025-09-07 08:37:03 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f04c10>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:03 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_d73935ffa67a848e7b2f23f94a49ee1c'), (b'openai-processing-ms', b'6134'), (b'x-envoy-upstream-service-time', b'6137'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v4OviNCEeYimPJ3SriyFVTGopluxuKbAL1iOLhnieoo-1757259430-1.0.1.1-f_ZFt4DHU9WAmLyzenx5rMmmdw0ilyo_p0ZMmKG83NObYUIjSNrtyiWR7nCKsvqI2TKlQp7G_oQKtjfZs6nzAYlp5H_OPJgOQIsr6T4T9Rw; path=/; expires=Sun, 07-Sep-25 16:07:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74906db3f237f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_d73935ffa67a848e7b2f23f94a49ee1c'), (b'openai-processing-ms', b'6134'), (b'x-envoy-upstream-service-time', b'6137'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v4OviNCEeYimPJ3SriyFVTGopluxuKbAL1iOLhnieoo-1757259430-1.0.1.1-f_ZFt4DHU9WAmLyzenx5rMmmdw0ilyo_p0ZMmKG83NObYUIjSNrtyiWR7nCKsvqI2TKlQp7G_oQKtjfZs6nzAYlp5H_OPJgOQIsr6T4T9Rw; path=/; expires=Sun, 07-Sep-25 16:07:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74906db3f237f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:10 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64053 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_078f684a4a2ce5fdf498cfbd7af66d9c'), (b'openai-processing-ms', b'7513'), (b'x-envoy-upstream-service-time', b'7517'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FzZWE2oPSaV5.sS97M55CZ6tayQ9p3A6rzmBynz8pjA-1757259431-1.0.1.1-7rTy59SCrSuuoQBp.zttUgCr9kkzYCFsHlxoP0IBq1DawGXmYbAIynHdZaKbH3d3oXFI6gUwjeuVAyeqKsmuSOX6CskeCl4LExMuQb6cMVg; path=/; expires=Sun, 07-Sep-25 16:07:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b749070d4db9fd-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_078f684a4a2ce5fdf498cfbd7af66d9c'), (b'openai-processing-ms', b'7513'), (b'x-envoy-upstream-service-time', b'7517'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FzZWE2oPSaV5.sS97M55CZ6tayQ9p3A6rzmBynz8pjA-1757259431-1.0.1.1-7rTy59SCrSuuoQBp.zttUgCr9kkzYCFsHlxoP0IBq1DawGXmYbAIynHdZaKbH3d3oXFI6gUwjeuVAyeqKsmuSOX6CskeCl4LExMuQb6cMVg; path=/; expires=Sun, 07-Sep-25 16:07:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b749070d4db9fd-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:11 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64056 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:64087 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:27 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:27 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff670>
2025-09-07 08:37:27 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff670>
2025-09-07 08:37:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:27 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116efffd0>
2025-09-07 08:37:27 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116efffd0>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:29 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64092 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:29 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6730>
2025-09-07 08:37:29 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6730>
2025-09-07 08:37:29 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:29 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:29 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f080d0>
2025-09-07 08:37:29 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f080d0>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_21364dee2514d460a59aaaaef37a1308'), (b'openai-processing-ms', b'6037'), (b'x-envoy-upstream-service-time', b'6041'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7499cc945ba42-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_21364dee2514d460a59aaaaef37a1308'), (b'openai-processing-ms', b'6037'), (b'x-envoy-upstream-service-time', b'6041'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b7499cc945ba42-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:33 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64086 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b5cc8722832ba3f014e4d23dd281448b'), (b'openai-processing-ms', b'5850'), (b'x-envoy-upstream-service-time', b'5873'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b749a79a48c4dd-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b5cc8722832ba3f014e4d23dd281448b'), (b'openai-processing-ms', b'5850'), (b'x-envoy-upstream-service-time', b'5873'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b749a79a48c4dd-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:35 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64091 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:64101 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.started
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:46 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6e50>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef6e50>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f06790>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f06790>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64106 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef94c0>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef94c0>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9670>
2025-09-07 08:37:46 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef9670>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:46 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_d4fc44c99510b9096cb1c04e47b08ccf'), (b'openai-processing-ms', b'5886'), (b'x-envoy-upstream-service-time', b'5891'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a11f8a3ec80-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_d4fc44c99510b9096cb1c04e47b08ccf'), (b'openai-processing-ms', b'5886'), (b'x-envoy-upstream-service-time', b'5891'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a11f8a3ec80-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:52 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64100 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_7ec697fd3bef4bbc224d0252846e7c9d'), (b'openai-processing-ms', b'8293'), (b'x-envoy-upstream-service-time', b'8296'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a13fbf308e7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:37:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_7ec697fd3bef4bbc224d0252846e7c9d'), (b'openai-processing-ms', b'8293'), (b'x-envoy-upstream-service-time', b'8296'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a13fbf308e7-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:37:55 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64105 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:64117 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:05 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116edd820>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116edd820>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f004c0>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f004c0>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64123 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cba9a0>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110cba9a0>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ee1220>
2025-09-07 08:38:05 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ee1220>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:05 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2ac42188575888b3fda59317d2f2d9fe'), (b'openai-processing-ms', b'3758'), (b'x-envoy-upstream-service-time', b'3762'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a866f05ec02-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2ac42188575888b3fda59317d2f2d9fe'), (b'openai-processing-ms', b'3758'), (b'x-envoy-upstream-service-time', b'3762'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a866f05ec02-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:38:09 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64115 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_e448d53425bf3e2003b6edba04adec93'), (b'openai-processing-ms', b'6520'), (b'x-envoy-upstream-service-time', b'6524'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a8a6a117537-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_e448d53425bf3e2003b6edba04adec93'), (b'openai-processing-ms', b'6520'), (b'x-envoy-upstream-service-time', b'6524'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74a8a6a117537-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:38:12 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64120 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:64140 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:33 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1a30>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1a30>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1160>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116ef1160>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64145 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f00070>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f00070>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f00a00>
2025-09-07 08:38:33 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f00a00>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_f5b56064d4a182017b6d314c82669226'), (b'openai-processing-ms', b'9413'), (b'x-envoy-upstream-service-time', b'9417'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74b34da17ded9-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_f5b56064d4a182017b6d314c82669226'), (b'openai-processing-ms', b'9413'), (b'x-envoy-upstream-service-time', b'9417'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74b34da17ded9-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:38:42 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64139 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449216'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'104ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b49565cc3139200a0a77075aaf9fb9b0'), (b'openai-processing-ms', b'10031'), (b'x-envoy-upstream-service-time', b'10035'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74b3529b27636-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:38:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449216'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'104ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b49565cc3139200a0a77075aaf9fb9b0'), (b'openai-processing-ms', b'10031'), (b'x-envoy-upstream-service-time', b'10035'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74b3529b27636-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:38:43 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64144 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:64158 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.started
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:54 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff430>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff430>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f03790>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f03790>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64163 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef1c0>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef1c0>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff5b0>
2025-09-07 08:38:54 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff5b0>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:38:54 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_dce9c2da98287fa9dc0fd2b635a0b0ab'), (b'openai-processing-ms', b'5381'), (b'x-envoy-upstream-service-time', b'5385'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74bbd8e1a5050-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_dce9c2da98287fa9dc0fd2b635a0b0ab'), (b'openai-processing-ms', b'5381'), (b'x-envoy-upstream-service-time', b'5385'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74bbd8e1a5050-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:00 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64162 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_6a037b3ff2301497e36d06808cbc27b0'), (b'openai-processing-ms', b'12535'), (b'x-envoy-upstream-service-time', b'12545'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74bbb2bcc7534-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_6a037b3ff2301497e36d06808cbc27b0'), (b'openai-processing-ms', b'12535'), (b'x-envoy-upstream-service-time', b'12545'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74bbb2bcc7534-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:07 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:07 - httpcore.connection - DEBUG - close.started
2025-09-07 08:39:07 - httpcore.connection - DEBUG - close.started
2025-09-07 08:39:07 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:39:07 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:64157 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:19 - httpcore.connection - DEBUG - close.started
INFO:     127.0.0.1:64192 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:19 - httpcore.connection - DEBUG - close.started
2025-09-07 08:39:19 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:39:19 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f08340>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f08340>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef400>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eef400>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
INFO:     127.0.0.1:64197 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff7c0>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff7c0>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff970>
2025-09-07 08:39:19 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116eff970>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64192 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64197 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64202 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64197 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_c043a47e425fc8e9ea5f0d65779f41e0'), (b'openai-processing-ms', b'6554'), (b'x-envoy-upstream-service-time', b'6559'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c58d915681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_c043a47e425fc8e9ea5f0d65779f41e0'), (b'openai-processing-ms', b'6554'), (b'x-envoy-upstream-service-time', b'6559'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c58d915681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:26 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64202 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64197 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_398212996a73ec649f6a2cb58b5747c0'), (b'openai-processing-ms', b'7836'), (b'x-envoy-upstream-service-time', b'7839'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c57c8a17670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_398212996a73ec649f6a2cb58b5747c0'), (b'openai-processing-ms', b'7836'), (b'x-envoy-upstream-service-time', b'7839'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c57c8a17670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64190 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:27 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_974f0211a973875f8ca8f8f0a8a4789f'), (b'openai-processing-ms', b'3066'), (b'x-envoy-upstream-service-time', b'3072'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c831844681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_974f0211a973875f8ca8f8f0a8a4789f'), (b'openai-processing-ms', b'3066'), (b'x-envoy-upstream-service-time', b'3072'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c831844681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:29 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64212 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64197 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_66497fe32f65b03a66024e74fc00599a'), (b'openai-processing-ms', b'6200'), (b'x-envoy-upstream-service-time', b'6203'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c8989237670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_66497fe32f65b03a66024e74fc00599a'), (b'openai-processing-ms', b'6200'), (b'x-envoy-upstream-service-time', b'6203'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c8989237670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64202 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:33 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b1873409905f3fe32baa3ceedb53a2ca'), (b'openai-processing-ms', b'8682'), (b'x-envoy-upstream-service-time', b'8686'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c97a9f9681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_b1873409905f3fe32baa3ceedb53a2ca'), (b'openai-processing-ms', b'8682'), (b'x-envoy-upstream-service-time', b'8686'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74c97a9f9681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:38 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_50ea3562fb0506835f4eace59b0fe7ef'), (b'openai-processing-ms', b'8136'), (b'x-envoy-upstream-service-time', b'8146'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cb10ad97670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_50ea3562fb0506835f4eace59b0fe7ef'), (b'openai-processing-ms', b'8136'), (b'x-envoy-upstream-service-time', b'8146'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cb10ad97670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64212 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:42 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2db5cc47a04ef5eb2d8290b779edeee1'), (b'openai-processing-ms', b'5095'), (b'x-envoy-upstream-service-time', b'5097'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cce99dd681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_2db5cc47a04ef5eb2d8290b779edeee1'), (b'openai-processing-ms', b'5095'), (b'x-envoy-upstream-service-time', b'5097'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cce99dd681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:43 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:39:51 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2025-09-07 08:39:51 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0c130>
2025-09-07 08:39:51 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0c130>
2025-09-07 08:39:51 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:51 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110615970> server_hostname='api.openai.com' timeout=5.0
2025-09-07 08:39:51 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0c0a0>
2025-09-07 08:39:51 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x116f0c0a0>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:51 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ef61d1c39dfed9dcd1624a78a7b91a46'), (b'openai-processing-ms', b'8973'), (b'x-envoy-upstream-service-time', b'9170'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cef3d54681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ef61d1c39dfed9dcd1624a78a7b91a46'), (b'openai-processing-ms', b'8973'), (b'x-envoy-upstream-service-time', b'9170'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74cef3d54681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_7aca86031e7187e2557fc292b8cf31b2'), (b'openai-processing-ms', b'10729'), (b'x-envoy-upstream-service-time', b'10743'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74ce5ae147670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_7aca86031e7187e2557fc292b8cf31b2'), (b'openai-processing-ms', b'10729'), (b'x-envoy-upstream-service-time', b'10743'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74ce5ae147670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:53 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64212 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64242 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:55 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64242 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
INFO:     127.0.0.1:64245 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_198a9b51a87294bd627191bb053af82f'), (b'openai-processing-ms', b'4989'), (b'x-envoy-upstream-service-time', b'4992'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d2229e076e8-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_198a9b51a87294bd627191bb053af82f'), (b'openai-processing-ms', b'4989'), (b'x-envoy-upstream-service-time', b'4992'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d2229e076e8-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:39:57 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64233 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
INFO:     127.0.0.1:64245 - "GET /api/v1/chat/threads/recent?limit=10 HTTP/1.1" 200 OK
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_193bf1c1606044b8a028e18bd2d4cce4'), (b'openai-processing-ms', b'4927'), (b'x-envoy-upstream-service-time', b'4977'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d39f8aa7670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_193bf1c1606044b8a028e18bd2d4cce4'), (b'openai-processing-ms', b'4927'), (b'x-envoy-upstream-service-time', b'4977'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d39f8aa7670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64241 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:40:00 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_84aacf4399e3b78fb419760be92efa8c'), (b'openai-processing-ms', b'7718'), (b'x-envoy-upstream-service-time', b'7722'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d418e85681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_84aacf4399e3b78fb419760be92efa8c'), (b'openai-processing-ms', b'7718'), (b'x-envoy-upstream-service-time', b'7722'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d418e85681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:04 - httpcore.connection - DEBUG - close.started
2025-09-07 08:40:04 - httpcore.connection - DEBUG - close.started
2025-09-07 08:40:04 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:40:04 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - send_request_body.complete
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:40:04 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ca63e37c51ab56e682065e82eac4ecd7'), (b'openai-processing-ms', b'5874'), (b'x-envoy-upstream-service-time', b'5876'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d59dd4a7670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449501'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_ca63e37c51ab56e682065e82eac4ecd7'), (b'openai-processing-ms', b'5874'), (b'x-envoy-upstream-service-time', b'5876'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d59dd4a7670-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:06 - httpcore.http11 - DEBUG - response_closed.complete
INFO:     127.0.0.1:64241 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_40448a5ab21d668b6d63e76252312084'), (b'openai-processing-ms', b'10338'), (b'x-envoy-upstream-service-time', b'10340'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d726c63681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 07 Sep 2025 15:40:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'450000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'449500'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'66ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-knjlzgxswesrudhiuqhfddgj'), (b'openai-project', b'proj_5U72iGaa6G8r6dGo2gXOIAt4'), (b'x-request-id', b'req_40448a5ab21d668b6d63e76252312084'), (b'openai-processing-ms', b'10338'), (b'x-envoy-upstream-service-time', b'10340'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'97b74d726c63681f-SEA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - response_closed.started
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:15 - httpcore.http11 - DEBUG - response_closed.complete
2025-09-07 08:40:15 - httpcore.connection - DEBUG - close.started
2025-09-07 08:40:15 - httpcore.connection - DEBUG - close.started
2025-09-07 08:40:15 - httpcore.connection - DEBUG - close.complete
2025-09-07 08:40:15 - httpcore.connection - DEBUG - close.complete
INFO:     127.0.0.1:64195 - "GET /api/v1/chat/health HTTP/1.1" 200 OK
